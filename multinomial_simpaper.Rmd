---
title: "Limiting behavioral choice to 2 options reduces inferential power in idenitfying
  frequency-dependent learning (towards a $K$-action puzzlebox)"
author: "Brendan J Barrett"
date: "12/1/2021"
output: pdf_document
---

```{r setup, include=FALSE}
library(rethinking)
knitr::opts_chunk$set(echo = TRUE)
master2 <- read.csv("conform_sims_fis2.csv")
master2 <- master2[,-1]
nsims <- 30
```

# Introduction

## Two action puzzle boxes
all of whiten shit, lucy's stuff, erica van de waal

## Frequency dependent learning
why its adaptive

why its of interest

studies of it

## Mutlinomial data is empirical studies of social learning
theoretical stuff and thet moragan paper

experiments of me and charlotte, anne baby names paper

sloanea

other studies that have dropped it-- chimp hand clasping and susan paper, baby names data set



## Varitation and Information in studies of social learning
variation in a population is necessary for change to occur. ignoring it realizes

variation is linked to entropy and info

in a binomial distribution variation is $(1-p)*p$ which has the highest information

Studies with high variance and entropy provide more information

Information can help us identify plausible causal mechanisms. or more reliable estimate target parameters of interest.

## when we can't add individuals or samples, add options

# Methods

## Simulate Data

### vary F

### vary K
```{r}
#load subsets
k2 <- master2[master2$k==2,]
k3 <- master2[master2$k==3,]
k4 <- master2[master2$k==4,]

k2m <- as.matrix(k2[,1:nsims])
k3m <- as.matrix(k3[,1:nsims])
k4m <- as.matrix(k4[,1:nsims])


##plots
#k=2
index <- which(k2$n==50)
dens( k2m[index,] , show.HPDI=0.999 , col="grey" , main="f=2,n=5,k=2" , xlim=c(0,10) )
curve(dlnorm(x, meanlog=0, sdlog=1), from=0, to=10 , add=TRUE , lty=2 , col=1)
#for (i in 1:ncol(f_samples)) dens(f_samples[,i] , add=TRUE ,  col=col.alpha("red" , alpha=0.1))
      ## i need to get simulated data ans posteriors stored
abline(v=2)
seq_l <- seq(from=0 , to=0.35 , length=nsims)
f_med_order <- order(apply(k2m , 2 , median)) 
f_med_sort <- sort(apply(k2m , 2 , median)) 
points(f_med_sort , seq_l , cex=0.3)
for(i in 1:nsims) segments( x0=HPDI(k2m[,f_med_order[i]])[[1]] , y0=seq_l[i] , x1=HPDI(k2m[,f_med_order[i]])[[2]], y1=seq_l[i] )

#k=3
index <- which(k3$n==50)

dens( k3m[index,] , show.HPDI=0.999 , col="grey" , main="f=2,n=5,k=3" , xlim=c(0,10) )
curve(dlnorm(x, meanlog=0, sdlog=1), from=0, to=10 , add=TRUE , lty=2 , col=1)
abline(v=2)
seq_l <- seq(from=0 , to=0.35 , length=nsims)
f_med_order <- order(apply(k3m , 2 , median)) 
f_med_sort <- sort(apply(k3m , 2 , median)) 
points(f_med_sort , seq_l , cex=0.3)
for(i in 1:nsims) segments( x0=HPDI(k3m[,f_med_order[i]])[[1]] , y0=seq_l[i] , x1=HPDI(k3m[,f_med_order[i]])[[2]], y1=seq_l[i] )

#k=4
index <- which(k4$n==50)

dens( k4m[index,] , show.HPDI=0.999 , col="grey" , main="f=2,n=5,k=4" , xlim=c(0,10) )
curve(dlnorm(x, meanlog=0, sdlog=1), from=0, to=10 , add=TRUE , lty=2 , col=1)
abline(v=2)
seq_l <- seq(from=0 , to=0.35 , length=nsims)
f_med_order <- order(apply(k4m , 2 , median)) 
f_med_sort <- sort(apply(k4m , 2 , median)) 
points(f_med_sort , seq_l , cex=0.3)
for(i in 1:nsims) segments( x0=HPDI(k4m[,f_med_order[i]])[[1]] , y0=seq_l[i] , x1=HPDI(k4m[,f_med_order[i]])[[2]], y1=seq_l[i] )

```

### vary N


## Statistical Model

### Definition 

### Prior Choice

# Results

